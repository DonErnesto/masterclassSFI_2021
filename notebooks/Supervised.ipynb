{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/DonErnesto/masterclassSFI_2021/blob/main/notebooks/BreakoutSession_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this \"notebook\", we can run Python commands, make plots, and make notes. \n",
    "\n",
    "The purpose of this notebook is to guide you through some approaches to outlier detection using Python, and give you an impression of what the various algorithms do. \n",
    "\n",
    "Note that there are two types of cells in this notebook: Markdown cells (that contain text, like this one), and Code cells (that execute some code, like the next cell). \n",
    "\n",
    "By clicking the Play button on a cell, we execute a code cell. Lines that start with a \"#\" are comments, and not executed. \n",
    "\n",
    "Your input is required whenever there is a Question (in that case: write in the Markdown cell) or whenever you find some 'xxxxx' in the code cell (in this case, some code needs to be fixed or completed).\n",
    "\n",
    "We start by importing our outlier data, by executing the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data import from Github\n",
    "!curl -O https://raw.githubusercontent.com/DonErnesto/masterclassSFI_2021/main/data/X_supervised.csv.zip\n",
    "!curl -O https://raw.githubusercontent.com/DonErnesto/masterclassSFI_2021/main/data/y_supervised.csv.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using pandas for data handling, and scikit-learn (sklearn) for various outlier detection algorithms. \n",
    "\n",
    "Also, we imported a self-made module (outlierutils.py) that will be used for inspecting our results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Package import: pandas for data handling and manipulation\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will load the data in a so-called DataFrame (a pandas object), and inspect it by plotting the N-top rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('X_supervised.csv.zip')\n",
    "# .head() returns a DataFrame, that consists of the first N (default: N=5) rows \n",
    "# of the DataFrame it is applied on\n",
    "X.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data describes credit card transactions, one transaction per row. \n",
    "\n",
    "As you may notice, all features are numeric. All Vx features were generated by compressing the original data using a mathematical operation called PCA. In reality, we always have to convert our data to a purely numerical form (however, we generally want to avoid losing touch of the meaning of the attributes, for instance reasons of explainability).\n",
    "\n",
    "In this case, it is advantageous because little pre-processing or interpretation is needed, and we can feed the data directly into any algorithm, which will save us time. \n",
    "\n",
    "Before proceeding, let us determine the dimensions of the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any realistic situation, we would not have access to labels (otherwise, we would be using a supervised approach) and typically know nothing about the fraction of positives. We will already give one fact away: the fraction of positive labels is about 0.3%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a homemade outlier score (5 minutes)\n",
    "We will generate an array with outlier scores, based on your own hand-made logic. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** what shape should this array have? (# rows, # columns)\n",
    "\n",
    "\n",
    "Answer: xxxxx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, let's demonstrate some dataframe operations, with a smaller demonstration dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's demonstrate the hints with a smaller dataframe (the first 5 rows):\n",
    "small_df = X.head(3).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we can delete (\"drop\") one, or more columns as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = small_df.drop(columns=['V1', 'V5']) # This drops the V1 and V5 column s\n",
    "small_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can select a single column by its name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A single column:\n",
    "small_df['Amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can select multiple columns (amongst others) using .iloc: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All rows, and the first 5 columns:\n",
    "small_df.iloc[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All rows, all columns except the last 10 ones:\n",
    "small_df.iloc[:, :-10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can use .max(axis=1) and .sum(axis=1) to get the max- and summation over all columns (this reduces the size of the dataframe from m rows x n columns to m rows. \n",
    "\n",
    "- Also, we can use .abs() to convert the values to absolute (this doesn't change the size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df.iloc[:, :10].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, create an outlier score using the previously shown concepts. \n",
    "\n",
    "It is recommended to drop a column (which one??) before doing so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some examples to make an outlier score below. Uncomment (remove the \"#\") to execute it.\n",
    "\n",
    "# If you want to drop a column, do this as follows:\n",
    "\n",
    "X = X.drop(columns= ['xxxxx']) # This will create a DataFrame without the 'xxxxx' column, and assign it to X again\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Some options below. Note that only the last executed line will be kept!\n",
    "\n",
    "# homemade_outlier_scores = X['Amount']\n",
    "# homemade_outlier_scores = X['V1'].abs()\n",
    "# homemade_outlier_scores = X.iloc[:, :10].abs().max(axis=1)\n",
    "# homemade_outlier_scores = xxxxx (your own score, if desired)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homemade_outlier_score = X.iloc[:, :-1].abs().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To verify the shape, add .shape to the dataframe and look at the output\n",
    "homemade_outlier_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using outlier algorithms to generate outlier scores (10 minutes)\n",
    "\n",
    "We will demonstrate some of the many readily available outlier algorithms to generate scores. \n",
    "\n",
    "Note that Python is an object-oriented programming language. We typically first make an instance of a class (an object, that we pre-configure), than we perform various tasks (methods) with it. \n",
    "\n",
    "First we need to import some more objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import LocalOutlierFactor\n",
    "!pip install seaborn==0.11.1 # Needed for plotting\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest neighbours algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a NearestNeighbors object, and use that. First, we may want to read some documentation regarding the NearestNeighbors class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most default settings seem ok for a start. An interesting parameter to change may however be n_neighbors.\n",
    "\n",
    "Set n_neighbors to a value that seems okay (giving no arguments will get you all default values, as far as defaults are given)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NearestNeighbors(n_neighbors= xxxxx )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the object ready to accept data. We can pass it the data using the .fit() method: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.fit(xxxxx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the \"heavy lifting\" is done by the kneighbors() method. \n",
    "It returns the distances to the first N points, and the index of the nearest point \n",
    "\n",
    "NB: this takes about 20-30 seconds for this dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_to_neighbors = nn.kneighbors()[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is m rows x N neighbors: for each point m, the distances to its N nearest neighbors. \n",
    "Taking the mean, the max, or the median or all reasonable approaches to get a single outlier score per point. \n",
    "\n",
    "Let's look at the values for the first point, point 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_to_neighbors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to compress this m x N data to an outlier score. We do this by determining the mean (or median, or min, or max, as you prefer) distance as an outlier score. Let us explore three options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_mean_outlier_scores = np.mean(distances_to_neighbors, axis=1)\n",
    "knn_median_outlier_scores = np.xxxxx\n",
    "knn_min_outlier_scores = np.xxxxx\n",
    "knn_max_outlier_scores = np.xxxxx\n",
    "\n",
    "knn_outlier_scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** is a high or a low score indicator for an outlier-ish point?\n",
    "\n",
    "Answer: xxxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:**  how may we interpret the median, min and max, in case N_neighbors is, say, 10?\n",
    "\n",
    "Answer: xxxxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forest algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?IsolationForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the number of estimators to 1000, which gives a less noisy result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iforest = IsolationForest(xxxx=xxxxx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we fit the forest (create 1'000 splitting trees) with .fit(), and let all our datapoints pass this tree and count the needed splits with .score_samples() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iforest.fit(X)\n",
    "iforest_outlier_scores = iforest.score_samples(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is a measure for the number of needed splits to isolate a point. \n",
    "\n",
    "**Question:** Is a high score or a low score an indication for a point being an outlier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mahalanobis distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_outlier_scores = EmpiricalCovariance().fit(X).mahalanobis(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR GMM: The scores are the probability of a point belonging to its most likely cluster, for each point. \n",
    "\n",
    "**Question:** Is a high score or a low score an indication for a point being an outlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case the scores need to be reversed, un-comment and execute the next line\n",
    "# gmm_outlier_scores = -gmm_outlier_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3: Plot and compare results\n",
    "\n",
    "In the next section, we will see how well our algorithms did. Note that this information is often not available for problems where we apply outlier detection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the labels, and a helper module\n",
    "!curl -O https://raw.githubusercontent.com/DonErnesto/masterclassSFI_2021/main/data/y.csv.zip\n",
    "!curl -O https://raw.githubusercontent.com/DonErnesto/masterclassSFI_2021/main/outlierutils.py\n",
    "y = pd.read_csv('y.csv.zip')['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from outlierutils import plot_top_N, plot_outlier_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing the conditional distributions of the scores, and the AUC metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_outlier_scores(y.values, np.log1p(homemade_outlier_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_outlier_scores(y.values, np.log1p(knn_mean_outlier_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_outlier_scores(y.values, np.log1p(-iforest_outlier_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_outlier_scores(y.values, np.log10(cov_outlier_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing the precision@top-N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_top_N(y_true=y, scores=homemade_outlier_scores, N=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_top_N(y_true=y, scores=knn_mean_outlier_scores, N=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_top_N(y_true=y, scores=-iforest_outlier_scores, N=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_top_N(y_true=y, scores=cov_outlier_scores, N=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** based on the number of positives, what precision do you expect when randomly guessing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
