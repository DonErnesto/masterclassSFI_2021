{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/DonErnesto/masterclassSFI_2021/blob/main/notebooks/CreditCardUnsupervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Detection with Unsupervised Outlier Detection\n",
    "\n",
    "\n",
    "**Introduction**\n",
    "\n",
    "The purpose of this Jupyter notebook is to take you through several unsupervised outlier detection algorithms, and show their value for the purpose of fraud detection. The completely different situation compared to the supervised case, is that we -assume to- have no or too few labels to learn from. This is typically the case in fraud detection, as fraudulent events are often very rare. In applying an outlier detection for fraud detection, we hypothesize that payment patterns that are \"untypical\" (i.e., outliers) are more likely to be fraudulent.  \n",
    "\n",
    "Generally, an unsupervised approach is taken only when there are no or too few labels available. For this masterclass, we do use a dataset that was labeled, but will not make use of those labels until after we made predictions to get a feeling of how the various algorithms perform and compare. \n",
    "\n",
    "The data is taken from https://www.kaggle.com/mlg-ulb/creditcardfraud, and has been downsampled for the purpose of this masterclass. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are two types of cells in this notebook: **markdown cells** (that contain text, like this one), and **code cells** (that execute some code, like the next cell). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data import from Github\n",
    "import os\n",
    "if not os.path.exists('X_unsupervised.csv.zip'):\n",
    "    !curl -O https://raw.githubusercontent.com/DonErnesto/masterclassSFI_2021/main/data/X_unsupervised.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the `pandas` package for data handling and manipulation, and later `scikit-learn` (imported with \"sklearn\") and `pyod` to obtain outlier detection algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# A small hack: \"monkey-patching\" the DataFrame class to add column-wise normalization as a method\n",
    "def normalize_columns(self,):\n",
    "    return (self - self.mean()) / self.std()\n",
    "pd.DataFrame.normalize_columns = normalize_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will load the data in a so-called DataFrame (with is a pandas object, and works much like an Excel sheet), and inspect it by plotting the first rows. \n",
    "\n",
    "We call the dataframe `X`, und use the DataFrames method `.head(n)` to display the top n rows (per default, n=5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('X_unsupervised.csv.zip')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The data has {len(X)} rows and {len(X.columns)} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data describes credit card transactions, one transaction per row. \n",
    "\n",
    "As you may have noticed, all features are numeric. All `Vx` features are the result of a mathematical operation called PCA. In reality we are often dealing with non-numerical data (text, categories, ...), that require some effort to be converted to numerical, making it suitable for the mathematical models we work with. Not having to deal with that complexity right now, we can go straight into the modelling part. \n",
    "\n",
    "Let us first determine the dimensions of the DataFrame (note that the first dimension goes along the rows, the second along columns):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment: Defining a homemade outlier score\n",
    "\n",
    "Generate an array with outlier scores based on your own hand-made logic. Store the outlier predictions in a pandas Series with the name \"homemade_outlier_scores\", using the examples below. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "\n",
    "Below, there are several options to create a hand-crafted outlier score. \n",
    "\n",
    "Which one would you chose, and why? Uncomment your preference, to assign the outcome to the variable 'homemade_outlier_scores'. If you see a better solution, you are free to implement that. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint*: the various methods that are used on the DataFrame are:\n",
    "\n",
    "- `.abs()` This method converts all values to absolute (and does not change the size of the DataFrame)\n",
    "- `.drop(columns=...)` This method drops the indicated columns (may be a string or a list of strings) \n",
    "- `.max(axis=1)` This method, when executed with axis=1, sums over all columns\n",
    "- `.mean(axis=1)` This method, with axis=1, takes the means over all columns \n",
    "\n",
    "Note that each of these methods return again a DataFrame. They may thus be executed one after the other (this is called \"method chaining\" in Python). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some examples to make an outlier score below. Uncomment (remove the \"#\") to execute it.\n",
    "\n",
    "# homemade_outlier_scores = X.drop(columns='Time').abs().max(axis=1)\n",
    "# homemade_outlier_scores = (X.normalize_columns()**2).mean(axis=1)\n",
    "# homemade_outlier_scores = X['Amount']\n",
    "# homemade_outlier_scores = X.drop(columns='Time').abs().max(axis=1) # .drop() returns the cropped dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To verify the shape, add .shape to the dataframe and look at the output. What shape should it be?\n",
    "# homemade_outlier_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Break-out session\n",
    "\n",
    "First run the cells below for important imports and to remove the \"Time\" column.\n",
    "\n",
    "Then go to the section of the outlier algorithm assigned to you or chosen by you below to generate your scores. Answer the questions belonging to your algorithm, and compare the results with those of your home-made algorithm (see section `Evaluation`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import EmpiricalCovariance\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "try:\n",
    "    import pyod\n",
    "except ModuleNotFoundError:\n",
    "    !pip install pyod\n",
    "from pyod.models.auto_encoder import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We consider Time to be not meaningful for outlier detection\n",
    "X = X.drop(columns='Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mahalanobis Distance\n",
    "\n",
    "The Mahalanobis distance is a generalization of distance (measured in standard deviations) to a multivariate normal distribution. The assumption being made is thus that the data is normally distributed, and that outliers are located further away from the center than the inliers. \n",
    "\n",
    "Run the cells below to: \n",
    "- Create an EmpiricalCovariance object\n",
    "- Fit the data to this model\n",
    "- Assign the scores to `mah_outlier_scores`, using the method `.mahalanobis()`, applied on the fitted object `cov`\n",
    "\n",
    "If necessary, add a `-` after the equals sign of the assignment (remember, we want outlier scores to be large for outliers). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?EmpiricalCovariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = EmpiricalCovariance()\n",
    "cov.fit(X)\n",
    "\n",
    "# cov is now an EmpiricalCovariance object that is fitted on the data X. \n",
    "# assign the mahalanobis scores using its .mahalanobis() method\n",
    "\n",
    "# mah_outlier_scores =  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the documentation to determine the correct sign for the scoring\n",
    "?cov.mahalanobis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: in which situation is the ranking by a Mahalonobis-distance score equivalent by a ranking based on a column-wise sum of squared values? In this case, is this so? \n",
    "\n",
    "*Hint*: You may use `.std()` on X the get the standard deviations along its ~30 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Mixture\n",
    "\n",
    "The Gaussian Mixture is a assumes the data consists of one or multiple \"blobs\" of clusters with some normal distribution (NB: with a co-variance matrix constrained to be spherical, diagonal or non-constrained - full). It is a \"soft clustering\" method, as each point may belong to each cluster with some probability. \n",
    "After fitting, the method .score_samples() returns some probability measure (probability density of the point within the gaussian mixture distribution). \n",
    "\n",
    "Run the cells below to: \n",
    "\n",
    "- Create a GaussianMixture object (you may adapt the parameters if desired)\n",
    "- Fit the object to the data\n",
    "- Get scores for the individual data points using `.score_samples()`\n",
    "\n",
    "If necessary, add a `-` after the equals sign of the assignment (remember, we want outlier scores to be large for outliers, read the documentation to decide this). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=5, covariance_type='spherical', random_state=1, n_init=3) \n",
    "gmm.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gmm is now an GaussianMixture object that is fitted on the data X. \n",
    "# assign the scores using its .score_samples() method, and argument X\n",
    "\n",
    "# gmm_scores = ... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?gmm.score_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: It is not trivial to know in advance a good value for the number of components. Can you think of a procedure to estimate it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest neighbours\n",
    "\n",
    "Neighbourhood-based algorithms look at the distances to a point's neighbours to determine its \"outlierness\". \n",
    "In the most basic NearestNeighbor algorithm as used here, the distance of a point to its neighbours is used to measure its outlierness. (The more involved LOF algorithm uses the deviation in local density of a data point with respect to its neighbors). \n",
    "\n",
    "Run the cells below to: \n",
    "- Create a NearestNeighbors object (adapt the parameters if you wish)\n",
    "- Fit the data to this model\n",
    "- Assign the scores to `knn_outlier_scores`, by aggregating the data in `distances_to_neighbors`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a NearestNeighbors object, and use that. First, we may want to read some documentation regarding the NearestNeighbors class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NearestNeighbors(n_neighbors=50)\n",
    "nn.fit(X)\n",
    "\n",
    "# Use the .kneighbors()[0] method to get the distances in the next line\n",
    "# distances_to_neighbors =   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"heavy lifting\" was done by the `.kneighbors()` method. \n",
    "It returns for each point the distances to the nearest N points, and the index of the nearest point. \n",
    "\n",
    "As a final step, we collapse this distance matrix (m points x N neighbours) to m scores. This may be done in several ways, for instance by taking the mean, or the median. Choose one of the options given below (by default, the mean is taken). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?nn.kneighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_outlier_scores = np.mean(distances_to_neighbors, axis=1)\n",
    "# knn_outlier_scores = np.median(distances_to_neighbors, axis=1)\n",
    "# knn_outlier_scores = np.max(distances_to_neighbors, axis=1)\n",
    "# knn_outlier_scores = np.min(distances_to_neighbors, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: what is an interpretation (say when n_neighbours is 11) for the\n",
    "\n",
    "- median\n",
    "- min\n",
    "- max\n",
    "\n",
    "distance to the n_neighbours? \n",
    "Why would you prefer one over the other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forest algorithm\n",
    "\n",
    "The isolation forest algorithm measures how difficult it is to isolate a point from the rest of the data, using a random splitting algorithm. Similar to the Random Forest algorithm, many (`n_estimators`) different trees are built, each time based on a randomly drawn sample (of size `max_samples`).\n",
    "\n",
    "Run the cells below to: \n",
    "- Create an IsolationForest object with the correct parameters\n",
    "- Fit the IsolationForest object with the data\n",
    "- Get the scores using `.score_samples()`\n",
    "\n",
    "If necessary, add a `-` after the equals sign of the assignment (remember, we want outlier scores to be large for outliers. Read the documentation, and note that the score as returned by `.score_samples()` is a measure for the number of needed splits to isolate a point). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iforest = IsolationForest(n_estimators=100, max_samples=1024, random_state=24)\n",
    "iforest.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the scores to the variable iforest_outlier_scores using the method .score_samples(),\n",
    "# giving X as an argument, taking into account the correct sign. \n",
    "# iforest_outlier_scores = ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?iforest.score_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** \n",
    "\n",
    "What advantage and disadvantage of this method do you see?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Autoencoder\n",
    "\n",
    "Autoencoders are a special type of neural networks, that are trained to effectively compress and decompress a signal. The idea behind using these networks for outlier detection, is that the neural network is expected to handle \"typical\" datapoints well, whereas it will struggle with outliers. \n",
    "\n",
    "We use the pyod `AutoEncoder` class to construct the network. This way we don't have to bother with the details of building the network, and can focus on the main parameters. \n",
    "\n",
    "Run the cells below to: \n",
    "- Create an Autoencoder object\n",
    "- Train this object on the data\n",
    "- Get the scores using .score_samples()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = MinMaxScaler().fit_transform(X)\n",
    "clf = AutoEncoder(\n",
    "    hidden_neurons=[10, 5, 10], # Choose bottleneck here!\n",
    "    hidden_activation='elu',\n",
    "    output_activation='sigmoid', \n",
    "    optimizer='adam',\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    dropout_rate=0.0, #may not be needed here\n",
    "    l2_regularizer=0.0,\n",
    "    validation_size=0.1,\n",
    "    preprocessing=False, #NB: this uses sklearn's StandardScaler\n",
    "    verbose=1,\n",
    "    random_state=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If necessary, add a `-` after the equals sign of the assignment (remember, we want outlier scores to be large for outliers. Read the documentation of `AutoEncoder`, especially regarding the attribute `decision_scores_`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign scores to the variable autoenc_outlier_scores, using the `clf.decision_scores_` attribute \n",
    "# NB: this is not a method, and does therefore not need to be called with `()`\n",
    "# autoenc_outlier_scores = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Why do you think we had to scale the data with a MinMaxScaler (hint: the signal needs to be reconstructed by the network). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "In the next section, you will compare how your algorithm did against your \"home-made\" algorithm, using the labels (ground-truth: is a point an outlier or not? In this case: is a transaction fraudulent or not?). \n",
    "Note that this information is usually not available for those problems where we decide to use outlier detection.\n",
    "\n",
    "\n",
    "Look carefully at the plots and assess their meaning. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the labels, and a helper module\n",
    "import os\n",
    "import pandas as pd\n",
    "force_download = False\n",
    "if force_download or not os.path.exists('y_unsupervised.csv.zip'): # then probably nothing was downloaded yet\n",
    "    !curl -O https://raw.githubusercontent.com/DonErnesto/masterclassSFI_2021/main/data/y_unsupervised.csv.zip\n",
    "if True or not os.path.exists('outlierutils.py'):\n",
    "    !curl -O https://raw.githubusercontent.com/DonErnesto/masterclassSFI_2021/main/outlierutils.py\n",
    "        \n",
    "y = pd.read_csv('y_unsupervised.csv.zip')['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from outlierutils import plot_top_N as ptn, plot_outlier_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional distributions of the scores, and the AUC metrics\n",
    "\n",
    "NB: \n",
    "- plot your \"homemade\" score and your own algorithm\n",
    "- use np.log1p(your_score) to logtransform your score if needed (in case it has a very long \"tail\")\n",
    "- if a variable name has a red squiggle underneath, it means that the variable doesn't exist. Executing a cell containing such a missing variable will result in a NameError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " _ = plot_outlier_scores(y.values, np.log1p(homemade_outlier_scores), title='Homemade: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_outlier_scores(y.values, np.log1p(mah_outlier_scores), title='Mahalonobis: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_outlier_scores(y.values, gmm_scores - min(gmm_scores), title='GMM: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_outlier_scores(y.values, np.log1p(knn_outlier_scores), title='KNN: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_outlier_scores(y.values, iforest_outlier_scores, title='Isolation Forest: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_outlier_scores(y.values, autoenc_outlier_scores, title='Autoencoder: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision@top-N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plots shows how many of the top-N points in terms of score were actual outliers (the more yellow the plot, the better the algorithm performed).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_top_N(y_true=y, scores=homemade_outlier_scores, N=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_top_N(y_true=y, scores=mah_outlier_scores, N=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_top_N(y_true=y, scores=gmm_scores, N=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_top_N(y_true=y, scores=knn_outlier_scores, N=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_top_N(y_true=y, scores=iforest_outlier_scores, N=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_top_N(y_true=y, scores=autoenc_outlier_scores, N=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "- Which home-made outlier model did you choose and why?\n",
    "- How did it perform?\n",
    "- What choices did you make for the outlier algorithm, if any, and why?\n",
    "- How did it perform, also relative to the home-made model?\n",
    "- Answers to the algorithm-specific questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
