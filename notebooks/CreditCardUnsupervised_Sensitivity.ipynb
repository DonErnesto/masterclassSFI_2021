{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/DonErnesto/masterclassSFI_2021/blob/main/notebooks/CreditCardUnsupervised_Sensitivity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Fraud Detection - Sensitivity Study\n",
    "\n",
    "\n",
    "**Introduction**\n",
    "\n",
    "\n",
    "The purpose of this Jupyter notebook is to show the sensitivity of the various models to changes in their parameters.\n",
    "\n",
    "\n",
    "The data was taken from https://www.kaggle.com/mlg-ulb/creditcardfraud, and downsampled for the purpose of this masterclass. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data import from Github\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "force_download = False\n",
    "if force_download or not os.path.exists('X_unsupervised.csv.zip'):\n",
    "    !curl -O https://raw.githubusercontent.com/DonErnesto/masterclassSFI_2021/main/data/X_unsupervised.csv.zip\n",
    "    !curl -O https://raw.githubusercontent.com/DonErnesto/masterclassSFI_2021/main/data/y_unsupervised.csv.zip\n",
    "    !curl -O https://raw.githubusercontent.com/DonErnesto/masterclassSFI_2021/main/ml_utils.py\n",
    "X = pd.read_csv('X_unsupervised.csv.zip')\n",
    "X = X.drop(columns='Time')\n",
    "y = pd.read_csv('y_unsupervised.csv.zip')['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the \"pandas\" package for data handling and manipulation, and later \"scikit-learn\" (imported with \"sklearn\") for various outlier detection algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier algorithms\n",
    "\n",
    "Go to the section of the outlier algorithm assigned to you or chosen by you to generate your scores. \n",
    "First run the cell below for important imports.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import LocalOutlierFactor\n",
    "# !pip install seaborn==0.11.1 # Needed for plotting\n",
    "# !pip install tensorflow\n",
    "# !pip install pyod\n",
    "import numpy as np\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    from pyod2.models.auto_encoder import AutoEncoder\n",
    "except ModuleNotFoundError:\n",
    "    !pip install pyod\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mahalanobis Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = EmpiricalCovariance()\n",
    "cov.fit(X)\n",
    "mah_outlier_scores = cov.mahalanobis(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Mahalanobis score: {roc_auc_score(y, mah_outlier_scores):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components_list = np.arange(2, 11)\n",
    "gmm_scores_list = []\n",
    "bic_list = []\n",
    "for n_components in n_components_list:\n",
    "    gmm = GaussianMixture(n_components=n_components, covariance_type='full', random_state=1, n_init=3) \n",
    "    gmm.fit(X)\n",
    "    gmm_scores_list.append(roc_auc_score(y, -gmm.score_samples(X)))\n",
    "    bic_list.append(gmm.bic(X))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(n_components_list, gmm_scores_list, 'g-', label='AUC')\n",
    "ax2.plot(n_components_list, bic_list, 'r-', label='BIC')\n",
    "plt.xticks(n_components_list)\n",
    "ax1.set_xlabel('# Components')\n",
    "ax1.set_ylabel('AUC score', color='g')\n",
    "ax2.set_ylabel('BIC', color='r')\n",
    "plt.title(\"AUC scores and BIC, GMM\", fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest neighbours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kN_list = [5, 11, 31, 71, 201]\n",
    "knn_scores_list = []\n",
    "for kN in kN_list:\n",
    "    nn = NearestNeighbors(n_neighbors=kN)\n",
    "    nn.fit(X)\n",
    "    distances_to_neighbors = nn.kneighbors()[0]\n",
    "    knn_outlier_scores = np.mean(distances_to_neighbors, axis=1)\n",
    "    knn_scores_list.append(roc_auc_score(y, knn_outlier_scores))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(kN_list, knn_scores_list, 'k-', label='AUC')\n",
    "plt.xticks(kN_list)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('AUC score', color='k')\n",
    "plt.title(\"AUC scores, kNN\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_sample_list = [2**N for N in np.arange(8, 13)]\n",
    "iforest_scores_list = [] \n",
    "for N_samples in N_sample_list:\n",
    "    iforest = IsolationForest(n_estimators=100, max_samples=N_samples)\n",
    "    iforest.fit(X)\n",
    "    iforest_scores_list.append(roc_auc_score(y, -iforest.score_samples(X)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(N_sample_list, iforest_scores_list, 'k-', label='AUC')\n",
    "plt.xticks(N_sample_list)\n",
    "plt.xlabel('max_samples')\n",
    "plt.ylabel('AUC score', color='k')\n",
    "plt.title(\"AUC scores, iForest\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Autoencoder\n",
    "\n",
    "Autoencoders are a special type of neural networks, that are trained to effectively compress and decompress a signal. The idea behind using these networks for outlier detection, is that the neural network is expected to handle \"typical\" datapoints well, whereas it will struggle with outliers. \n",
    "\n",
    "We use the pyod AutoEncoder class to construct the network. This way we can focus on the main parameters. \n",
    "\n",
    "Run the cells below to: \n",
    "- Create an Autoencoder object\n",
    "- Train this object on the data\n",
    "- Get the scores using .score_samples()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoenc_scores = []\n",
    "X_scaled = MinMaxScaler().fit_transform(X)\n",
    "add_width_list = np.array([0, 2, 4, 6])\n",
    "mid_width = 3\n",
    "end_width = 8\n",
    "for add_width in add_width_list:\n",
    "    clf = AutoEncoder(\n",
    "        hidden_neurons=[end_width+add_width, mid_width+add_width, end_width+add_width], # Choose bottleneck here!\n",
    "        hidden_activation='elu',\n",
    "        output_activation='sigmoid', \n",
    "        optimizer='adam',\n",
    "        epochs=5,\n",
    "        batch_size=16,\n",
    "        dropout_rate=0.0, #may not be needed here\n",
    "        l2_regularizer=0.0,\n",
    "        validation_size=0.1,\n",
    "        preprocessing=False, #NB: this uses sklearn's StandardScaler\n",
    "        verbose=1,\n",
    "        random_state=1,\n",
    "    )\n",
    "    clf.fit(X_scaled)\n",
    "    autoenc_scores.append(roc_auc_score(y, clf.decision_scores_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(add_width_list + mid_width, autoenc_scores, 'k-', label='AUC')\n",
    "plt.xticks(add_width_list + mid_width)\n",
    "plt.xlabel('Bottleneck width')\n",
    "plt.ylabel('AUC score', color='k')\n",
    "plt.title(\"AUC scores, Autoencoder\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
