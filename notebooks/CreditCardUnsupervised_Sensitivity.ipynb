{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/DonErnesto/masterclassSFI_2021/blob/main/notebooks/CreditCardUnsupervised_Sensitivity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Fraud Detection - Sensitivity Study\n",
    "\n",
    "\n",
    "**Introduction**\n",
    "\n",
    "\n",
    "The purpose of this Jupyter notebook is to show the sensitivity of the various models to changes in their parameters.\n",
    "\n",
    "\n",
    "The data was taken from https://www.kaggle.com/mlg-ulb/creditcardfraud, and downsampled for the purpose of this masterclass. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data import from Github\n",
    "\n",
    "import os\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "force_download = False\n",
    "if force_download or not os.path.exists('X_unsupervised.csv.zip'):\n",
    "    !curl -O https://raw.githubusercontent.com/DonErnesto/masterclassSFI_2021/main/data/X_unsupervised.csv.zip\n",
    "    !curl -O https://raw.githubusercontent.com/DonErnesto/masterclassSFI_2021/main/data/y_unsupervised.csv.zip\n",
    "    !curl -O https://raw.githubusercontent.com/DonErnesto/masterclassSFI_2021/main/ml_utils.py\n",
    "X = pd.read_csv('X_unsupervised.csv.zip')\n",
    "X = X.drop(columns='Time')\n",
    "y = pd.read_csv('y_unsupervised.csv.zip')['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the \"pandas\" package for data handling and manipulation, and later \"scikit-learn\" (imported with \"sklearn\") for various outlier detection algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier algorithms\n",
    "\n",
    "Go to the section of the outlier algorithm assigned to you or chosen by you to generate your scores. \n",
    "First run the cell below for important imports.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "try:\n",
    "    import pyod\n",
    "except ModuleNotFoundError:\n",
    "    !pip install pyod\n",
    "from pyod.models.auto_encoder import AutoEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mahalanobis Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = EmpiricalCovariance()\n",
    "cov.fit(X)\n",
    "mah_outlier_scores = cov.mahalanobis(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Mahalanobis score: {roc_auc_score(y, mah_outlier_scores):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components_list = np.arange(2, 11)\n",
    "gmm_scores_list = []\n",
    "bic_list = []\n",
    "for n_components in tqdm.tqdm(n_components_list):\n",
    "    gmm = GaussianMixture(n_components=n_components, covariance_type='full', random_state=1, n_init=3) \n",
    "    gmm.fit(X)\n",
    "    gmm_scores_list.append(roc_auc_score(y, -gmm.score_samples(X)))\n",
    "    bic_list.append(gmm.bic(X))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(n_components_list, gmm_scores_list, 'g-', label='AUC')\n",
    "ax2.plot(n_components_list, bic_list, 'r-', label='BIC')\n",
    "plt.xticks(n_components_list)\n",
    "ax1.set_xlabel('# Components')\n",
    "ax1.set_ylabel('AUC score', color='g')\n",
    "ax2.set_ylabel('BIC', color='r')\n",
    "plt.title(\"AUC scores and BIC, GMM\", fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest neighbours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kN_list = [5, 11, 31, 71, 201]\n",
    "knn_scores_list = []\n",
    "for kN in tqdm.tqdm(kN_list):\n",
    "    nn = NearestNeighbors(n_neighbors=kN)\n",
    "    nn.fit(X)\n",
    "    distances_to_neighbors = nn.kneighbors()[0]\n",
    "    knn_outlier_scores = np.mean(distances_to_neighbors, axis=1)\n",
    "    knn_scores_list.append(roc_auc_score(y, knn_outlier_scores))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(kN_list, knn_scores_list, 'k-', label='AUC')\n",
    "plt.xticks(kN_list)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('AUC score', color='k')\n",
    "plt.title(\"AUC scores, kNN\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_sample_list = [2**N for N in np.arange(8, 13)]\n",
    "iforest_scores_list = [] \n",
    "for N_samples in tqdm.tqdm(N_sample_list):\n",
    "    iforest = IsolationForest(n_estimators=100, max_samples=N_samples, random_state=24)\n",
    "    iforest.fit(X)\n",
    "    iforest_scores_list.append(roc_auc_score(y, -iforest.score_samples(X)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(N_sample_list, iforest_scores_list, 'k-', label='AUC')\n",
    "plt.xticks(N_sample_list)\n",
    "plt.xlabel('max_samples')\n",
    "plt.ylabel('AUC score', color='k')\n",
    "plt.title(\"AUC scores, iForest\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Autoencoder\n",
    "\n",
    "Autoencoders are a special type of neural networks, that are trained to effectively compress and decompress a signal. The idea behind using these networks for outlier detection, is that the neural network is expected to handle \"typical\" datapoints well, whereas it will struggle with outliers. \n",
    "\n",
    "We use the pyod AutoEncoder class to construct the network. This way we can focus on the main parameters. \n",
    "\n",
    "Run the cells below to: \n",
    "- Create an Autoencoder object\n",
    "- Train this object on the data\n",
    "- Get the scores using .score_samples()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoenc_scores = []\n",
    "X_scaled = MinMaxScaler().fit_transform(X)\n",
    "add_width_list = np.array([0, 2, 4, 6])\n",
    "mid_width = 3\n",
    "end_width = 8\n",
    "for add_width in tqdm.tqdm(add_width_list):\n",
    "    clf = AutoEncoder(\n",
    "        hidden_neurons=[end_width+add_width, mid_width+add_width, end_width+add_width], # Choose bottleneck here!\n",
    "        hidden_activation='elu',\n",
    "        output_activation='sigmoid', \n",
    "        optimizer='adam',\n",
    "        epochs=5,\n",
    "        batch_size=16,\n",
    "        dropout_rate=0.0, #may not be needed here\n",
    "        l2_regularizer=0.0,\n",
    "        validation_size=0.1,\n",
    "        preprocessing=False, #NB: this uses sklearn's StandardScaler\n",
    "        verbose=1,\n",
    "        random_state=1,\n",
    "    )\n",
    "    clf.fit(X_scaled)\n",
    "    autoenc_scores.append(roc_auc_score(y, clf.decision_scores_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(add_width_list + mid_width, autoenc_scores, 'k-', label='AUC')\n",
    "plt.xticks(add_width_list + mid_width)\n",
    "plt.xlabel('Bottleneck width')\n",
    "plt.ylabel('AUC score', color='k')\n",
    "plt.title(\"AUC scores, Autoencoder\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
