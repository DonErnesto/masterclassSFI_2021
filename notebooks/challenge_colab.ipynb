{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DonErnesto/amld2020-unsupervised/blob/master/notebooks/challenge_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ek6rUiPXRC-"
   },
   "source": [
    "# Workshop challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FsyJ1d24Z9Je"
   },
   "source": [
    "## Package installing and data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "brdJ1IWkc2UK",
    "outputId": "24ea451a-434e-470c-9e6b-cdb94920df04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: curl: not found\n",
      "/bin/sh: 1: curl: not found\n"
     ]
    }
   ],
   "source": [
    "# Now only load the required files...\n",
    "\n",
    "!curl -O https://raw.githubusercontent.com/amld/workshop-unsupervised-fraud/master/outlierutils.py\n",
    "!curl -O https://raw.githubusercontent.com/amld/workshop-unsupervised-fraud/master/data/x_kdd.pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "eI3sCkfBZoXX",
    "outputId": "3f2178ef-e537-4d64-d043-7312dbfdf49c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyod\n",
      "  Downloading pyod-0.8.8.tar.gz (102 kB)\n",
      "\u001b[K     |████████████████████████████████| 102 kB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib in /Users/ernstoldenhof/Projects/MasterclassSFI2021/venv/lib/python3.7/site-packages (from pyod) (1.0.1)\n",
      "Requirement already satisfied: matplotlib in /Users/ernstoldenhof/Projects/MasterclassSFI2021/venv/lib/python3.7/site-packages (from pyod) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.13 in /Users/ernstoldenhof/Projects/MasterclassSFI2021/venv/lib/python3.7/site-packages (from pyod) (1.20.2)\n",
      "Collecting numba>=0.35\n",
      "  Downloading numba-0.53.1-cp37-cp37m-macosx_10_14_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.25 in /Users/ernstoldenhof/Projects/MasterclassSFI2021/venv/lib/python3.7/site-packages (from pyod) (1.2.3)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/ernstoldenhof/Projects/MasterclassSFI2021/venv/lib/python3.7/site-packages (from pyod) (1.6.2)\n",
      "Requirement already satisfied: scikit_learn>=0.19.1 in /Users/ernstoldenhof/Projects/MasterclassSFI2021/venv/lib/python3.7/site-packages (from pyod) (0.24.1)\n",
      "Requirement already satisfied: six in /Users/ernstoldenhof/Projects/MasterclassSFI2021/venv/lib/python3.7/site-packages (from pyod) (1.15.0)\n",
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.12.2-cp37-cp37m-macosx_10_15_x86_64.whl (9.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.5 MB 8.2 MB/s eta 0:00:01     |██████▊                         | 2.0 MB 4.9 MB/s eta 0:00:02     |██████████▋                     | 3.1 MB 4.9 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/ernstoldenhof/Projects/MasterclassSFI2021/venv/lib/python3.7/site-packages (from numba>=0.35->pyod) (54.1.2)\n",
      "Collecting llvmlite<0.37,>=0.36.0rc1\n",
      "  Downloading llvmlite-0.36.0-cp37-cp37m-macosx_10_9_x86_64.whl (18.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 18.5 MB 8.6 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /Users/ernstoldenhof/Projects/MasterclassSFI2021/venv/lib/python3.7/site-packages (from pandas>=0.25->pyod) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/ernstoldenhof/Projects/MasterclassSFI2021/venv/lib/python3.7/site-packages (from pandas>=0.25->pyod) (2.8.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ernstoldenhof/Projects/MasterclassSFI2021/venv/lib/python3.7/site-packages (from scikit_learn>=0.19.1->pyod) (2.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ernstoldenhof/Projects/MasterclassSFI2021/venv/lib/python3.7/site-packages (from matplotlib->pyod) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/ernstoldenhof/Projects/MasterclassSFI2021/venv/lib/python3.7/site-packages (from matplotlib->pyod) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/ernstoldenhof/Projects/MasterclassSFI2021/venv/lib/python3.7/site-packages (from matplotlib->pyod) (8.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/ernstoldenhof/Projects/MasterclassSFI2021/venv/lib/python3.7/site-packages (from matplotlib->pyod) (2.4.7)\n",
      "Collecting patsy>=0.5\n",
      "  Using cached patsy-0.5.1-py2.py3-none-any.whl (231 kB)\n",
      "Building wheels for collected packages: pyod\n",
      "  Building wheel for pyod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyod: filename=pyod-0.8.8-py3-none-any.whl size=116965 sha256=a2005b6c2355e168b63ae691a1b09d03c109a5b2d030a7c4f0696abe976bd425\n",
      "  Stored in directory: /Users/ernstoldenhof/Library/Caches/pip/wheels/77/59/4c/18e7ef198e2c737674b0bd8b6fa0fb1163c83ecc4e622fbda4\n",
      "Successfully built pyod\n",
      "Installing collected packages: patsy, llvmlite, statsmodels, numba, pyod\n",
      "Successfully installed llvmlite-0.36.0 numba-0.53.1 patsy-0.5.1 pyod-0.8.8 statsmodels-0.12.2\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/Users/ernstoldenhof/Projects/MasterclassSFI2021/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install pyod package\n",
    "!pip install pyod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PpkjzX_2XRDD"
   },
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_MZmQrSTXRDF",
    "outputId": "ef404de3-cb2b-4f31-88cb-2b88935efb6e"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c41f5590e8a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# pyod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_encoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlof\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLOF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/MasterclassSFI2021/venv/lib/python3.7/site-packages/pyod/models/auto_encoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseDetector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase_dl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_get_tensorflow_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# if tensorflow 2, import from tf directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/MasterclassSFI2021/venv/lib/python3.7/site-packages/pyod/models/base_dl.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_tensorflow_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# %tensorflow_version 1.x\n",
    "# standard library imports\n",
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "\n",
    "# pandas, seaborn etc.\n",
    "#import seaborn as sns\n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# sklearn outlier models\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "# from sklearn.neighbors import LocalOutlierFactor\n",
    "# from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# other sklearn functions\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.covariance import MinCovDet, EmpiricalCovariance\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import scale as preproc_scale\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# pyod\n",
    "import pyod\n",
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.lof import LOF\n",
    "# from pyod.models.pca import PCA as pyod_PCA\n",
    "from pyod.models.iforest import IForest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hDdOJyUvZaeZ"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'outlierutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8221b20b83d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0moutlierutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_top_N\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_outlier_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLabelSubmitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://unsupervised-label-api-pg.herokuapp.com/\"\u001b[0m \u001b[0;31m# Link to the API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'outlierutils'"
     ]
    }
   ],
   "source": [
    "from outlierutils import plot_top_N, plot_outlier_scores, LabelSubmitter \n",
    "url = \"https://unsupervised-label-api-pg.herokuapp.com/\" # Link to the API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set size: (48113, 79)\n"
     ]
    }
   ],
   "source": [
    "data_path = '.'\n",
    "x_kdd = pd.read_pickle(os.path.join(data_path, 'x_kdd.pkl'))\n",
    "x_kdd = x_kdd.drop_duplicates()\n",
    "if x_kdd.index.max() > len(x_kdd):\n",
    "    x_kdd = x_kdd.reset_index()\n",
    "print(f'Data set size: {x_kdd.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Description\n",
    "\n",
    "You just imported a data set, `x_kdd`, with 48K rows. The dataset was collected by by MIT Lincoln Labs in 1999, by operating a LAN-network as usual, and additionally carrying out various attacks. This specific dataset (which is a subset of the original dataset) has \"normal\" traffic as inlier class, and several attacks (buffer_overflow, ftp_write, imap, ...) as outlier class. Although this data does not represent payment fraud, it is relevant because of the mixed data type. \n",
    "\n",
    "\n",
    "There are no labels available, there is therefore also no split in train and test. \n",
    "The target is to predict as many true positives as possible (each positive gets you a positive score), and as few false positives as possible (each false positive subtracts a small score). So only submit points that may likely be positives!!\n",
    "\n",
    "\n",
    "Be selective, just submitting all points, or random points, will not get you a good score :)\n",
    "\n",
    "- Each true positive found yields **500** points\n",
    "- Each false positive costs **25** points\n",
    "\n",
    "**Hints**\n",
    "\n",
    "- The fraction of positives is less than 1%. Random guessing to gather labels is therefore unlikely to pay off. \n",
    "- When sufficiently many positive labels are available, this information may be used to further tune unsupervised algorithms, or to train a supervised classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First clean up the data: convert categorical columns to one-hot encoded, and MinMax-scale all features. Do not remove any rows!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean-up code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier detection: your code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_N_indices(scores, N=100):\n",
    "    \"\"\" Helper function. Returns the indices of the points with the top N highest outlier scores\n",
    "    \"\"\"\n",
    "    return np.argsort(scores)[::-1][:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_N_indices(np.array([5, 4, 3, 2, 1, 0]), N=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API submission\n",
    "\n",
    "Submit your predictions to the API with a LabelSubmitter object. \n",
    "This object has a `.post_predictions()` method to submit predictions, and a `.get_labels()` method to retrieve the labels (positives and negatives) of all previous submissions. \n",
    "\n",
    "Use the parameter `endpoint='kdd'` option for both methods for this challenge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the username and password correct?\n"
     ]
    }
   ],
   "source": [
    "username='xxx'\n",
    "password='xxx'\n",
    "if not ('ls' in locals() and ls.jwt_token): #only if no labelsubmitter with .jwt_token is available\n",
    "    ls = LabelSubmitter(username=username,\n",
    "                       password=password,\n",
    "                       url=url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ls.post_predictions(idx=predictions, endpoint='kdd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ls.get_labels(endpoint='kdd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "challenge_colab.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
